<!DOCTYPE html>
<html  lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

      <title>Machine Learning API: Getting Started</title>
    
          <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
          <link rel="stylesheet" href="../_static/theme.css " type="text/css" />
      
      <!-- sphinx script_files -->
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>

      
      <!-- bundled in js (rollup iife) -->
      <!-- <script src="../_static/theme-vendors.js"></script> -->
      <script src="../_static/theme.js" defer></script>
    
      <link rel="shortcut icon" href="../_static/favicon.png"/>
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Engines: pyvar.ml.engines" href="pyvar.ml.engines.html" />
  <link rel="prev" title="Machine Learning API" href="../pyvar.ml.html" /> 
  </head>

  <body>
    <div id="app">
    <div class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="../index.html" class="home-link">
    
      <img class="logo" src="../_static/logo.png" alt="logo"/>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="../search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="../index.html#useful-links">Table of Contents</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 ">
            
              <a href="../pyvar.gettingstarted.html" class="reference internal ">Getting Started</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../pyvar.cm.html" class="reference internal ">Cortex-M API</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../pyvar.ml.html" class="reference internal ">Machine Learning API</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../pyvar.multimedia.html" class="reference internal ">Multimedia API</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../pyvar.quickexamples.html" class="reference internal ">Quick Examples</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../pyvar.license.html" class="reference internal ">LICENSE</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../pyvar.contribute.html" class="reference internal ">Contribute</a>
            

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
    
      <li><a href="../pyvar.ml.html">Machine Learning API</a> &raquo;</li>
    
    <li>Machine Learning API: Getting Started</li>
  </ul>
  

  <ul class="page-nav">
  <li class="prev">
    <a href="../pyvar.ml.html"
       title="previous chapter">← Machine Learning API</a>
  </li>
  <li class="next">
    <a href="pyvar.ml.engines.html"
       title="next chapter">Engines: pyvar.ml.engines →</a>
  </li>
</ul>
  
</div>
<hr>
          <div class="content" role="main" v-pre>
            
  <section id="machine-learning-api-getting-started">
<h1>Machine Learning API: Getting Started<a class="headerlink" href="#machine-learning-api-getting-started" title="Permalink to this heading">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>Before getting started with the pyvar package and learning more about its core and
examples, it is important to mention that one of the main focuses of this package
is to allow the users to explore multiple ML applications use cases by using
displays, cameras devices, and user interfaces capabilities. We also must
briefly talk about a few more things such as the AI hardware accelerator,
model training, and model quantization, although those are extensive subjects.</p>
<p>The comprehension of the above topics might help you to understand how does ML work on
embedded systems, and it will probably allow you to get the best possible
inference performance on your ML applications.</p>
</section>
<section id="hardware">
<h2>Hardware<a class="headerlink" href="#hardware" title="Permalink to this heading">¶</a></h2>
<section id="recommended-system-on-modules-soms">
<h3>Recommended System on Modules (SoMs)<a class="headerlink" href="#recommended-system-on-modules-soms" title="Permalink to this heading">¶</a></h3>
<p>To achieve the best possible performance on ML applications, it is recommended to
use the System on Modules powered by the i.MX 8M Plus or i.MX 93 processors from
NXP. Check the SoMs below:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><a class="reference external" href="https://www.variscite.com/product/system-on-module-som/cortex-a53-krait/var-som-mx8m-plus-nxp-i-mx-8m-plus/">VAR-SOM-MX8M-PLUS</a></p></th>
<th class="head"><p><a class="reference external" href="https://www.variscite.com/product/system-on-module-som/cortex-a53-krait/dart-mx8m-plus-nxp-i-mx-8m-plus/">DART-MX8M-PLUS</a></p></th>
<th class="head"><p><a class="reference external" href="https://www.variscite.com/product/system-on-module-som/cortex-a55/var-som-mx93-nxp-i-mx-93/">VAR-SOM-MX93</a></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="../_images/var-som-mx8m-plus.png"><img alt="var-mplus" src="../_images/var-som-mx8m-plus.png" style="width: 100%;" /></a></p></td>
<td><p><a class="reference internal" href="../_images/dart-mx8m-plus.png"><img alt="dart-mplus" src="../_images/dart-mx8m-plus.png" style="width: 90%;" /></a></p></td>
<td><p><a class="reference internal" href="../_images/var-som-mx93.png"><img alt="var-93" src="../_images/var-som-mx93.png" style="width: 100%;" /></a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="i-mx-8m-plus-neural-processing-unit-npu-overview">
<h3>i.MX 8M Plus: Neural Processing Unit (NPU) Overview<a class="headerlink" href="#i-mx-8m-plus-neural-processing-unit-npu-overview" title="Permalink to this heading">¶</a></h3>
<p>The above MPlus SoMs have a dedicated unit to deal with the ML inference process called
Neural Processing Unit provided by Verisilicon. This compute engine delivers up
to <strong>2.3</strong> Tera Operations Per Second (<em>TOPS</em>) and handles 8-bit fixed-point
operations models, allowing the user to achieve the highest performance during
the inference process.</p>
<p>The pyvar package is not tied to the NPU only, so you can use any other SoM from
the i.MX8 family with the ML API. What changes is that the inference process
runs on the GPU/CPU instead of the NPU, and this may probably result on a higher
inference time due to more complex calculations.</p>
<p>The NPU itself handles 8-bit fixed-point operations, which results in the ability
to have a ML model with a much simpler and smaller arithmetic units avoiding
larger floating points calculations. To utilize the computation capabilities by
achieving the best possible inference performance of this unit, the model must
be converted from a 32-bit floating-point network into an 8-bit fixed point network.</p>
<p>This conversion is known as quantization, and there are two possible options to
quantize a model to properly work on the NPU. The first one is to train your own
model by applying the quantization-aware training (QAT) method during training;
a simpler option is to use a post-training method that only converts a
trained model to the format NPU requires. Check out our <a class="reference external" href="https://github.com/varigit/var-demos/tree/master/machine-learning-demos/tflite/python/imx8mplus">var-demos-plus</a> repository
for more source code samples, and simple post-training example.</p>
<ul class="simple">
<li><p>For more information about the NPU, please check this <a class="reference external" href="https://www.nxp.com/products/processors-and-microcontrollers/arm-processors/i-mx-applications-processors/i-mx-8-processors/i-mx-8m-plus-arm-cortex-a53-machine-learning-vision-multimedia-and-industrial-iot:IMX8MPLUS">page</a>.</p></li>
</ul>
</section>
<section id="i-mx-93-ethos-u65-micronpu-neural-processing-unit-overview">
<h3>i.MX 93: Ethos u65 microNPU (Neural Processing Unit) Overview<a class="headerlink" href="#i-mx-93-ethos-u65-micronpu-neural-processing-unit-overview" title="Permalink to this heading">¶</a></h3>
<p>The i.MX 93 is slightly different from the i.MX8M Plus when we need to run
Machine Learning examples on the NPU. For more information, please read the
following <a class="reference external" href="https://www.nxp.com/docs/en/user-guide/IMX-MACHINE-LEARNING-UG.pdf">document</a> from NXP.</p>
<p>Basically, we should not use the libvxdelegate library anymore, this is only for
the 8 family. We need to use the ethosu library to load the model to the microNPU
for the i.MX 93. Check the difference:</p>
<ul>
<li><p><strong>i.MX 8M Plus</strong></p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tflite_runtime.interpreter</span> <span class="kn">import</span> <span class="n">Interpreter</span>
<span class="n">interpreter</span> <span class="o">=</span> <span class="n">Interpreter</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;path/to/the/model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p><strong>i.MX 93</strong></p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ethosu.interpreter</span> <span class="k">as</span> <span class="nn">ethosu</span>
<span class="n">interpreter</span> <span class="o">=</span> <span class="n">ethosu</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="s2">&quot;path/to/the/model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
<p>Firstly, we need to take the model and convert it to use on the Ethos u65
microNPU. We load the converted model (vela) using the TensorFlow Lite API
(ethosu library), then the engine calls the Ethos-U Linux driver and dispatches
the customized Ethos-U operator to the Ethos-U firmware on Cortex-M reaching the
Ethos-U NPU.</p>
<p><strong>Installing the Ethos-u-Vela Tool</strong></p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/nxp-imx/ethos-u-vela.git cd &amp;&amp; ethos-u-vela</span>
<span class="go">git checkout lf-5.15.71_2.2.0</span>
<span class="go">pip3 install .</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Converting the model using Ethos-u-Vela</strong></p>
<blockquote>
<div><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">vela model_example.tflite</span>
</pre></div>
</div>
</div></blockquote>
<p>Then, you will get the <strong>model_example_vela.tflite</strong> model.</p>
<p>Check out our <a class="reference external" href="https://github.com/varigit/var-demos/tree/master/machine-learning-demos/tflite/python/imx93">var-demos-93</a> repository for more source code samples, and
simple post-training example.</p>
</section>
</section>
</section>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
  <li class="prev">
    <a href="../pyvar.ml.html"
       title="previous chapter">← Machine Learning API</a>
  </li>
  <li class="next">
    <a href="pyvar.ml.engines.html"
       title="next chapter">Engines: pyvar.ml.engines →</a>
  </li>
</ul><div class="footer" role="contentinfo">
      &#169; Copyright 2021-2022 Variscite LTD.
</div>
            </div>
          </div>
      </page>
    </div></div>
    
    
  </body>
</html>